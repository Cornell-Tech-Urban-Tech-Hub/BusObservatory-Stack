{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping live bus feed \n",
    "(based on \"get the newest parquet in the data lake\" method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_id=\"tfnsw_buses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "bucket_name=\"bus-observatory-staging\"\n",
    "prefix = f\"feeds/tfnsw_bus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Key': 'feeds/tfnsw_bus/INCOMING_tfnsw_bus_2023-03-30_18_33_57.parquet', 'LastModified': datetime.datetime(2023, 3, 30, 22, 34, tzinfo=tzutc()), 'ETag': '\"e7c65707c278335b4a7e5cf71892bd8b\"', 'Size': 125069, 'StorageClass': 'STANDARD'}\n"
     ]
    }
   ],
   "source": [
    "# after https://stackoverflow.com/questions/45375999/how-to-download-the-latest-file-of-an-s3-bucket-using-boto3\n",
    "\n",
    "import boto3\n",
    "\n",
    "def get_most_recent_s3_object(bucket_name, prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "    paginator = s3.get_paginator( \"list_objects_v2\" )\n",
    "    page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "    latest = None\n",
    "    for page in page_iterator:\n",
    "        if \"Contents\" in page:\n",
    "            latest2 = max(page['Contents'], key=lambda x: x['LastModified'])\n",
    "            if latest is None or latest2['LastModified'] > latest['LastModified']:\n",
    "                latest = latest2\n",
    "    return latest\n",
    "\n",
    "latest = get_most_recent_s3_object(bucket_name, prefix)\n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 7: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m s3_object_body \u001b[39m=\u001b[39m s3_response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mBody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Read the data in bytes format and convert it to string\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m content_str \u001b[39m=\u001b[39m s3_object_body\u001b[39m.\u001b[39;49mread()\u001b[39m.\u001b[39;49mdecode()\n\u001b[1;32m     19\u001b[0m \u001b[39m# Print the file contents as a string\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(content_str)\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 7: invalid start byte"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import geopandas as gpd\n",
    "import io\n",
    "\n",
    "# Set up an Amazon S3 client object\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Retrieve the Parquet file from S3\n",
    "\n",
    "response = s3.get_object(Bucket=bucket_name, Key=latest['Key'])\n",
    "parquet_object = response['Body'].read()\n",
    "\n",
    "# Create an in-memory buffer from the Parquet file\n",
    "buffer = io.BytesIO(parquet_object)\n",
    "\n",
    "# Read the data from the in-memory buffer and create a GeoDataFrame\n",
    "gdf = gpd.read_parquet(buffer)\n",
    "\n",
    "# Work with the GeoDataFrame as required\n",
    "print(gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it into a geodataframe\n",
    "# https://janakiev.com/blog/pandas-pyarrow-parquet-s3/#reading-parquet-file-from-s3-as-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to geojson and return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
